{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rabeya/opt/anaconda3/lib/python3.7/site-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix as cmatrix\n",
    "\n",
    "import umap\n",
    "import sklearn\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's do a object-oriented programming approach to creating a \n",
    "# classifier based on Bayesian inference\n",
    "\n",
    "# a bayesian classifier must: \n",
    "# 1) take in as input training and test data,\n",
    "# 2) calculate \"priors\" of the classes based on training data,\n",
    "# 3) decide on a way to calculate likelihoods (KDE density or Gaussian mixture)\n",
    "# 4) finally, do posterior odds ratio prediction (or probabilities) by combining\n",
    "# priors with likelihoods \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------the main Bayesian classifier class------------------------------\n",
    "\n",
    "class BayesClassifier:\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.categories = np.unique(y)\n",
    "        self.log_priors = None\n",
    "        self.log_likelihoods = None\n",
    "        self.X_features = None\n",
    "        self.model_dict = None\n",
    "        \n",
    "    def preprocess(self, n_features):\n",
    "        Fext = FeatureExtractor(self.X, self.y)\n",
    "        Fext.train_test_split().get_features(num_features=n_features)\n",
    "        self.X_features = Fext.features_extracted\n",
    "        self.y_train, self.y_test, self.X_test = Fext.y_train, Fext.y_test, Fext.X_test\n",
    "        # calculate priors here\n",
    "        \n",
    "        \n",
    "    def use_model(self, model_type):\n",
    "        # model_type is the type of model. KernelDensity or GaussianMixture (from sklearn) work as values\n",
    "        if ( model_type is sklearn.neighbors.KernelDensity ):\n",
    "            Model = LikelihoodModel(self.X_features, self.y_train, sklearn.neighbors.KernelDensity)\n",
    "            Model.fit()\n",
    "            self.model_dict = Model.model_dict\n",
    "        elif ( model_type is sklearn.mixture.GaussianMixture ):\n",
    "            Model = LikelihoodModel(self.X_features, self.y_train, sklearn.mixture.GaussianMixture)\n",
    "            Model.fit()\n",
    "            self.model_dict = Model.model_dict\n",
    "        # now calculate likelihoods\n",
    "        frequencies = pd.Series(self.y_train).value_counts(normalize=True)\n",
    "        \n",
    "    \n",
    "    \n",
    "    def predict(self):\n",
    "        predictions = []\n",
    "        # this function will do the actual posterior class prediction \n",
    "        # we add the log_priors + log_likelihoods = log_posteriors (up to proportion) \n",
    "        if is_image(self.X_test):\n",
    "            X_test_reshaped = np.reshape(self.X_test, (len(self.X_test), -1))\n",
    "            for i in range(0, X_test_reshaped.shape[0]):\n",
    "                test_point = X_test_reshaped[i,:]\n",
    "                # for each row (data-point) in the test data-matrix\n",
    "                \n",
    "        elif is_tabular(self.X_test):\n",
    "            for i in range(0, X_test.shape[0]):\n",
    "                test_point = self.X_test[i,:]\n",
    "                \n",
    "        #pass\n",
    "    \n",
    "    def visualize(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "# ----------------------------------------the likelihood model-building class-------------------------------------\n",
    "\n",
    "class LikelihoodModel:\n",
    "    def __init__(self, X, y, model_type):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.categories = np.unique(y)\n",
    "        self.model_dict = None \n",
    "        self.model_type = model_type # the model inputted here \n",
    "    \n",
    "    def fit(self):\n",
    "        category_models = []\n",
    "        for category in self.categories:\n",
    "            category_index = np.where( self.y==category )\n",
    "            X_category = self.X[category_index]\n",
    "            # get input about parameter grid used on model\n",
    "            # now check for the model type\n",
    "            if ( self.model_type is sklearn.neighbors.KernelDensity ):\n",
    "                # fill in parameter dictionary\n",
    "                key = input('Enter parameter name: ')\n",
    "                start = float(input('Enter start value: '))\n",
    "                end = float(input('Enter end value: '))\n",
    "                step = float(input('# of points? '))\n",
    "                param_grid = {key: np.logspace(start, end, step)}\n",
    "                # grid-search\n",
    "                optimal_model = find_best_params( X_category, KernelDensity(kernel='gaussian'), param_grid )\n",
    "                category_models.append( optimal_model )\n",
    "            # otherwise if the model is Gaussian Mixture \n",
    "            elif ( self.model_type is sklearn.mixture.GaussianMixture ):\n",
    "                # fill in parameter dictionary\n",
    "                key = input('Enter parameter name: ')\n",
    "                n_components = int(input('# of components? ')) \n",
    "                param_grid = {key: np.asarray(list(range(1, n_components+1))) }\n",
    "                # grid-search\n",
    "                optimal_model = find_best_params( X_category, GaussianMixture(n_components=n_components), param_grid )\n",
    "                category_models.append( optimal_model )    \n",
    "        # put all the models for each category into the model_dict instance variable        \n",
    "        self.model_dict = {('Model {i}'.format(i)):m for (i,m) in enumerate(category_models)}\n",
    "        \n",
    "    def visualize(self):\n",
    "        # first, choose a model from the self.model_dict\n",
    "        \n",
    "        pass\n",
    "        \n",
    "        \n",
    "\n",
    "#----------------------------------------the feature extractor class----------------------------------------\n",
    "        \n",
    "class FeatureExtractor:\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.features_extracted = None\n",
    "        self.feature_names = None\n",
    "        \n",
    "    def train_test_split(self, train_percent=70):\n",
    "        self.X_train, self.X_test,\\ \n",
    "        self.y_train, self.y_test = sklearn.model_selection.train_test_split(self.X, self.y, \n",
    "                                                                             train_size=(train_percent/100),\n",
    "                                                                            random_state=2)\n",
    "    def get_features(self, num_features=2):\n",
    "        if is_tabular(self.X_train):\n",
    "            # if data is tabular\n",
    "            # we can use random forest feature_importance method\n",
    "            if ( numpy.isnan(self.X_train).any() or numpy.isnan(self.y_train).any() ):\n",
    "                # first check if any missing values\n",
    "                # so if either condition is true, there are missing values\n",
    "                return 'Your data-matrix or target-class has missing values. Please fill them in first.'\n",
    "            else:\n",
    "                # data is all complete, do random forest feature extractor\n",
    "                RF = RandomForestClassifier(random_state=2)\n",
    "                RF.fit(self.X_train, self.y_train)\n",
    "                self.features_extracted = RF.feature_importances_[0:num_features] #need to sort from highest to lowest\n",
    "                print('{} best features extracted!'.format(num_features))\n",
    "        elif is_image(self.X_train):\n",
    "            # we can only use UMAP\n",
    "            # we need to first reshape self.X_train from 3D numpy array to 2D array\n",
    "            X_train_reshaped = np.reshape(self.X_train, (len(self.X_train), -1))\n",
    "            # then use UMAP\n",
    "            mapper = umap.UMAP(n_components=num_features, random_state=2).fit(X_train_reshaped)\n",
    "            umap_features = mapper.transform(X_train_reshaped)\n",
    "            self.features_extracted = umap_features\n",
    "            print('{} best features extracted!'.format(num_features))\n",
    "            \n",
    "\n",
    "            \n",
    "            \n",
    "#-----------------------------------------auxiliary functions-------------------------------------------\n",
    "\n",
    "def find_best_params(X, model_inst, param_grid):\n",
    "    if ( isinstance(model_inst,sklearn.neighbors.KernelDensity) ):\n",
    "        grid = GridSearchCV( estimator=model_inst, \n",
    "                                param_grid=param_grid, n_jobs=-1 )\n",
    "        grid.fit(X)\n",
    "        best_model = sklearn.neighbors.KernelDensity(kernel='gaussian', grid.best_params[list(param_grid)[0]])\n",
    "        best_model.fit(X)\n",
    "    elif ( isinstance(model_inst,sklearn.mixture.GaussianMixture) ):\n",
    "        grid = GridSearchCV( estimator=model_inst, \n",
    "                                param_grid=param_grid, n_jobs=-1 )\n",
    "        grid.fit(X)\n",
    "        best_model = sklearn.mixture.GaussianMixture(n_components=grid.best_params[list(param_grid)[0]])\n",
    "        best_model.fit(X)\n",
    "    else:\n",
    "        return 'Error handling user-inputted model instance name.'\n",
    "    return best_model\n",
    "\n",
    "\n",
    "def is_tabular(X):\n",
    "    # check the dimensions of the data-matrix\n",
    "    # if it is 2-dimensional numpy array, its tabular\n",
    "    if (X.ndim == 2):\n",
    "        return True\n",
    "    elif:\n",
    "        return False\n",
    "\n",
    "def is_image(X):\n",
    "    # check the dimensions of the data-matrix\n",
    "    # if it is 3-dimensional numpy array, its image\n",
    "    if (X.ndim == 3):\n",
    "        return True\n",
    "    elif:\n",
    "        return False                  \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(GaussianMixture(n_components=5), sklearn.mixture.GaussianMixture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Kern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
